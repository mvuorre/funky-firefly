---
title: 'Bias no more: Introduction to latent group-mean centering in hierarchical bayesian models'
shorttitle: Latent group-mean centering
leftheader: Latent group-mean centering
author: 
  - name: Matti Vuorre
    affiliation: 1
    corresponding: yes
    address: Tilburg University
    email: m.j.vuorre@tilburguniversity.edu
  - name: Author 2
    affiliation: 2
    address: 
    email: 

affiliation:
  - id: 1
    institution: Tilburg University
  - id: 2
    institution: Institution 2

authornote: |
  \noindent \textit{This manuscript is not yet peer-reviewed.}
  
abstract: |
  Researchers studying links between observed variables in longitudinal and other repeated measures data sets have long recognized the importance of person-mean centering in order to isolate within- and between-person associations. However, a critical issue in centering---treating the person means as unknown parameters rather than observed values---has received less attention among applied practitioners. One reason for this has been the general unavailability and perceived complexity of latent person-mean centering in contrast to observed mean centering. Here, we introduce latent person-mean centering and accessible syntax for implementing it in a wide variety of flexible bayesian models with the R package brms. We demonstrate the syntax, and benefits of latent centering, through an example analysis of social media effects on adolescent well-being. In appendices, we further contrast the performance of latent mean centering to observed mean centering via simulations, and show how it extends to more than two levels of analysis. Latent mean centering provides unbiased estimates of within- and between-person associations, and we hope that the availability and flexibility of our proposed approach motivates researchers to apply this method widely in longitudinal and other multilevel modelling scenarios.
  
keywords: longitudinal data, repeated measures, centering, well-being, technology effects
wordcount: "`r wordcountaddin:::word_count(filename = 'ms.Rmd')`"
bibliography: "references.bib"
floatsintext: yes
linenumbers: no
draft: no
mask: no
figurelist: no
tablelist: no
footnotelist: no
documentclass: apa7
classoption: jou
output: 
  papaja::apa6_pdf:
    number_sections: false
    keep_tex: false
  papaja::apa6_docx: 
    number_sections: false
---

```{r setup, include = FALSE}
library(papaja)
library(citr)
library(parameters)
library(posterior)
library(lme4)
library(knitr)
library(scales)
library(ggdist)
library(brms)
library(tidyverse)

# Document options
opts_chunk$set(
  cache = TRUE,
  echo = FALSE
)

# HMC and parallel computation options
MAX_CORES <- as.numeric(Sys.getenv("MAX_CORES"))
if (is.na(MAX_CORES)) MAX_CORES <- parallelly::availableCores(logical = FALSE)
if (require(cmdstanr)) {
  options(
    brms.backend = "cmdstanr", 
    brms.threads = MAX_CORES %/% 4
  )
}

# Save models in a directory
dir.create("models", FALSE)

# Plotting options
theme_set(
  theme_linedraw(base_size = 10) +
    theme(
      strip.background = element_rect(fill = "gray90", color = "gray90"),
      strip.text = element_text(color = "black", hjust = 0),
      panel.grid = element_blank()
    )
)
```

```{r data-download}
# Download data if not downloaded
path <- "data/beyens-et-al-2021.csv"
dir.create(dirname(path), FALSE)
if (!file.exists(path)) 
  download.file("https://uvaauas.figshare.com/ndownloader/files/28057809", path)

# Load and clean
d <- read_csv(path) %>%
  # Subset data to a handful of participants' evening observations
  filter(
    BeepTE1 == 6,
    ID %in% sample(.$ID, 30)
  ) %>% 
  mutate(
    person = factor(ID),
    time = BeepNE1,
    # Sum of all passive use in the past hour
    sm = rowSums(select(., INP01E1, INP02E1, WAP01E1, SNP01E1, SNP02E1), na.rm = TRUE),
    # It can exceed 60 if p reported multiple overlapping uses
    sm = if_else(sm > 60, 60, sm),
    happy = AWBE1,
    .keep = "none"
  ) %>% 
  # Drop missing data
  drop_na(sm, happy)

# Lagged and centered variables
d <- d %>% 
  # Lag happiness by person
  mutate(
    happy1 = lag(happy), 
    .by = person
  ) %>% 
  # Grand mean center so between-person component is centered on zero
  mutate(
    smg = sm - mean(sm, na.rm = TRUE)
  ) %>% 
  # Calculate person means and person-specific deviations therein
  mutate(
    smb = mean(smg, na.rm = TRUE), 
    smw = smg - smb,
    happy1w = happy1 - mean(happy1, na.rm = TRUE),
    .by = person
  )
```


# Introduction

In longitudinal and other repeated measures data where predictors are observed associations can emerge at two (or more) levels: Between individuals and within individuals [@bolgerIntensiveLongitudinalMethods2013]. Because these two levels of analysis can embody different theoretical constructs, researchers have widely recognized the importance of centering the data appropriately, such that within-person associations can be estimated independently from between-person associations [@endersCenteringPredictorVariables2007]. If this distinction between sources of variance is not made, the resulting estimates are likely to be confusing mixtures of associations that occur between individuals and within individuals [@cronbachResearchClassroomsSchools1976 p.18; @raudenbushHierarchicalLinearModels2002 p.138]. Specifically, when a predictor can vary at two levels---observations varying around a person's average, and persons' averages varying around the global average---it is common to manipulate the data such that the analysis distinguishes those two levels.

In typical applications, a predictor is separated into two components: First, each individual's mean is calculated. Including the person mean as predictor in a regression model will describe the extent to which individuals with different average levels of the predictor differ on the outcome variable. Second, the individuals' means are subtracted from each observation, leading to a variable that indicates deviations around each person's average. This latter variable represents pure within-person variability. Including it as a model predictor leads to estimating how the outcome differs at different levels of the predictor, for the average person. Typically, it is this latter within-person association that is of key theoretical interest in psychology: It can be used to describe a counterfactual causal scenario where increasing the predictor for an individual leads to changes in that person's outcome [@rohrerTheseAreNot2021].

While simple to implement, this data manipulation trick has one potentially severe shortcoming: It can lead to biases in the estimated regression coefficients, especially when the number of observations per person is small. These biases result from ignoring the uncertainty inherent in the person means: They can only be estimated based on a sample of limited data, but simple calculations cannot carry this uncertainty forward into the resulting estimates. While this issue is recognized in the methodological literature [e.g. @asparouhovLatentVariableCentering2019; @mcneishPrimerTwolevelDynamic2020], practical implementations to overcome it have so far been limited to commercial solutions, most prominently the SEM software MPlus. In this manuscript, we provide a practical tutorial on latent mean centering in the context of longitudinal and repeated measures data in psychology. We implement latent mean centering in a series of multilevel models using the brms R package. Our aim is to provide this illustrative code so that latent mean centering can be more widely adopted within the psychological sciences.

In appendix A(?), we also conduct a simulation study to illustrate the conditions under which latent mean centering is most useful: As the number of observations per participant decreases, the beneficial debiasing effect of latent mean centering becomes more noticeable and important. In addition, while previous work has focused on latent mean centering specifically in the context of longitudinal datasets and timeseries analyses, we point out that it is a more general issue and applicable to datasets with potentially multiple levels of analysis? In appendix B, we extend the syntax to a three level model where latent means are estimated for adolescents nested within classes?

# Latent mean centering tutorial

In this example analysis, we examine a longitudinal dataset of Dutch adolescents' social media use and well-being. The authors of the original research article have made their valuable data openly available, which we appreciate. The sample consists of 387 Dutch adolescents (mean age: 14, 54% girls), who answered 34,930 experience sampling questions about their well-being ("How happy do you feel right now?"; 1: "Not at all", 4: "A little", 7: "Completely") and social media use. For this analysis, we used the sum of passive Instagram, WhatsApp, and Snapchat reported in the past hour. We show a snippet of this data in Table \@ref(tab:tab-data).

```{r}
#| label: tab-data
d %>% 
  slice(1:3, .by = person) %>% 
  head() %>% 
  apa_table(
    caption = "Six rows of example data", 
    note = "sm = passive social media use; smg = grand-mean centered sm; smb = between-person sm; smw = within-person sm; happyw1 = within-person lagged happiness rating.",
    col_spanners = list(`Original data` = c(1, 5), `Centered values` = c(6, 9)),
    digits = c(0, 0, 0, 0, 0, 0, 1, 1, 1), 
    font_size = "small", 
    span_text_columns = FALSE
  )
```

Table \@ref(tab:tab-data) shows the three first observations of two randomly selected participants from the sample. The first four columns contain an anomyous person identifier, the observation time point (an increasing integer), the number of minutes of passive social media use in the past hour, and the happiness rating. Then, for illustration, we have created three additional columns containing the centered social media use variables. The first, "smg", is the simple grand-mean centered "sm" variable. This variable is not required in all analyses. However, it can be used to zero-center the between-person variable if it is of interest. "smb" is the between-person component, which is simply that person's sample mean. "smw" is the deviation of the social media use value on that row from the person's mean, and thus the within-person component.

We loosely follow the authors' original analysis, which focused on the associations between social media use and happiness. To ground our tutorial on common practices, we first ignore latent mean centering, and describe the analysis in terms of the observed values. In this analysis, we are interested in the within- and between-person associations between passive social media use in the past hour and current well-being. To do so, we define a multilevel model of happiness ratings on both "smw" and "smb", and allow for random variability in person-specific averages in happiness ratings, and the association between happiness ratings and "smw". 

**Throw in a line here about why the autoregressive term is included.**

In typical R formula syntax, generalized for multilevel models in the lme4 package, this model is




which translates to the mixed effects model in Box 1. This model returns three key population-level estimates---parameter values assumed to hold for the average person in the population from which the sample was drawn: An intercept, slope of "smb", and slope of "smw". The first describes the happiness level of an average individual who passively used an average amount of social media in the past hour, and 

```{r}
#| eval: false
model <- bf(
  happy ~ b0happy + b1happy*(happy1 - b0happy) + b2happy*(sm - b0sm),
  b0happy ~ 1 + (1 | person),
  b1happy ~ 1 + (1 | person),
  b2happy ~ 1 + (1 | person),
  b0sm ~ 1 + (1 | person),
  nl = TRUE,
  center = FALSE
) +
  gaussian()

# Set priors
p <- prior(normal(30, 15), class = b, coef = Intercept, nlpar = b0sm)

fit <- brm(
  model,
  data = d,
  prior = p,
  cores = MAX_CORES,
  threads = THREADS,
  iter = ITER,
  control = list(adapt_delta = 0.99),
  file = "models/brm-fit-1"
)
summary(fit, prior = TRUE)
```


# Discussion

R [@rcoreteamLanguageEnvironmentStatistical2022]

# Author Contributions

Conceptualization: MV
Methodology: MV
Software: MV
Validation: MV
Formal Analysis: MV
Data Curation: MV
Writing -- Original Draft: MV
Writing -- Review & Editing: MV
Visualization: MV
Supervision: MV
Project Administration: MV

# Conflicts of Interest

The author(s) declare that there were no conflicts of interest with respect to the authorship or the publication of this article.

# Acknowledgements

We thank everyone who contributed to this discussion on the Stan discussion board (https://web.archive.org/web/20230207111825/https://discourse.mc-stan.org/t/latent-mean-centering-latent-covariate-models-in-brms/29424).

# References

::: {#refs custom-style="Bibliography"}
:::


<!-- Create an appendix with new page, table, and figure numbers. -->

\clearpage
\onecolumn

# Appendix Z: Simulation study

<!-- Prepend table & figure numbers with S and reset counters -->
\setcounter{page}{1}
\setcounter{table}{0}
\setcounter{figure}{0}
\renewcommand{\thetable}{A\arabic{table}}
\renewcommand{\thefigure}{A\arabic{figure}}

Hereafter be monsters and dragons.

Here, we conduct a small simulation study to verify that the proposed estimation method recovers specified parameter values.

We simulate data from a bivariate model of $x$ and $y$ measured over $i$ timepoints from 1 to $I$ and for $j$ subjects in 1 to $J$. In this simulation, we set $J = 30$ and vary $I$ from 6 to 60. Both variables are gaussian, with $x$ a simple random variable with a person-varying mean $\alpha_x$, and $y$ is affected by its previous value and the previous value of $x$.

\begin{align*}
x_{ij} &\sim \operatorname{Normal}(\alpha_{xj}, \sigma^2_x) \\
y_{ij} &\sim \operatorname{Normal}(
  \alpha_{yj} +
  \beta_{1j}(y_{[i-1]j} - \alpha_{yj}) +
  \beta_{2j}(x_{[i-1]j} - \alpha_{xj}), 
  \sigma^2_y
) \\ \\
\begin{bmatrix} 
  \alpha_x \\ \alpha_y \\ \beta_1 \\ \beta_2
\end{bmatrix} &\sim \operatorname{MVN}(
\begin{bmatrix} 
  \bar{\alpha}_x \\ \bar{\alpha}_y \\ \bar{\beta}_1 \\ \bar{\beta}_2
\end{bmatrix}, \mathbf{\Sigma}) \\ \\
\Sigma &= \mathbf{SRS} \\ \\
\mathbf{S} &= \begin{bmatrix} 
  \tau_0 &0 &0 &0 \\ 
  0 &\tau_1 &0 &0\\ 
  0 &0 &\tau_2 &0 \\ 
  0 &0 &0 &\tau_3
\end{bmatrix} \\ \\
\mathbf{R} &= 
\begin{bmatrix} 
  1 &\rho_{\alpha_x\alpha_y} &\rho_{\alpha_x\beta_1} &\rho_{\alpha_x\beta_2} \\ 
  \rho_{\alpha_x\alpha_y} &1 &\rho_{\alpha_y\beta_1} &\rho_{\alpha_y\beta_2} \\ 
  \rho_{\alpha_x\beta_1} &\rho_{\alpha_y\beta_1} &1 &\rho_{\beta_1\beta_2} \\ 
  \rho_{\alpha_x\beta_2} &\rho_{\alpha_y\beta_2} &\rho_{\beta_1\beta_2} &1 \\
\end{bmatrix}.
\end{align*}

```{r}
# Run simulations
# Save simulation results to file for every nr_individuals * nr_time
dir.create("sims", FALSE)

# Load function to simulate data
source("Generation_Code.r")

# Specify population level parameters
pop <- tibble(
  sigma_x = 1.0,
  sigma_y = 1.0,
  cor_xy = 0.0,
  alpha_x = 0.0,
  alpha_y = 0.0,
  tau_alpha_x = 0.5,
  tau_alpha_y = 0.5,
  cor_alpha = 0.2,
  beta_yy1 = 0.3,
  beta_yx = 0.25,
  beta_xy = 0.0,
  beta_xx1 = 0.0,
  tau_beta_yy1 = 0.1,
  tau_beta_yx = 0.2,
  tau_beta_xy = 0.0,
  tau_beta_xx1 = 0.0,
  cor_beta = 0.0
)

# Save empty brms model
model <- bf(
  y ~ alphay + betayy*(ylag - alphay) + betayx*(xlag - alphax),
  alphax + alphay + betayy + betayx ~ 1 + (1 |i| individual),
  nl = TRUE
) +
  gaussian()
p <- prior(normal(0, 1), class = b, coef = Intercept, nlpar = alphax) +
  prior(normal(0, 1), class = b, coef = Intercept, nlpar = alphay) +
  prior(normal(0, 1), class = b, coef = Intercept, nlpar = betayy) +
  prior(normal(0, 1), class = b, coef = Intercept, nlpar = betayx) +
  prior(lkj(2), class = cor, group = individual) +
  prior(student_t(7, 0, 1), class = sd, group = individual, nlpar = alphax) +
  prior(student_t(7, 0, 1), class = sd, group = individual, nlpar = alphay) +
  prior(student_t(7, 0, 0.5), class = sd, group = individual, nlpar = betayy) +
  prior(student_t(7, 0, 0.5), class = sd, group = individual, nlpar = betayx)
fit_brms_empty <- brm(
  model,
  data = simulate_twolevel_data()$data[[1]],
  prior = p,
  control = list(adapt_delta = 0.95),
  chains = 0,
  file = "models/brm-fit-empty"
)

# Function to estimate parameters
simulate_estimate <- function(nr_indiv = 30, nr_time = 10, iter = 2) {
  path <- str_glue("sims/nr_indiv-{nr_indiv}__nr_time-{nr_time}.rds")
  if (!file.exists(path)) {
    
    library(furrr)
    plan(multisession, workers = 8)
    
    sims <- pop %>% 
      # Cross design with sample sizes and simulation iterations
      crossing(
        nr_indiv = nr_indiv,
        nr_time = nr_time,
        i = 1:iter
      ) %>% 
      # Generate sets of person level parameters and data
      mutate(out = pmap(., simulate_twolevel_data)) %>% 
      unnest(out) %>% 
      nest(pop_pars = -c(i, nr_indiv, nr_time, indiv_pars, data))
    
    sims <- sims %>% 
      mutate(
        lmer = future_map(
          data,
          ~lmer(y ~ ylag_c + xlag_c + (ylag_c + xlag_c | individual), data = .x) %>% 
            parameters(effects = "all", group_level = TRUE) %>% 
            tibble() %>% 
            suppressMessages() %>% 
            suppressWarnings()
        )
      )
    
    sims <- sims %>% 
      mutate(
        brms = map(
          data,
          ~update(
            fit_brms_empty, 
            newdata = .x,
            cores = MAX_CORES,
            recompile = FALSE,
            threads = 2,
            iter = 2000
          ) %>% 
            parameters(centrality = "mean", effects = "all", group_level = TRUE, test = NULL) %>% 
            tibble()
        )
      )
    
    saveRDS(sims, path)
  } else {sims <- readRDS(path)}
  sims
}

# Run for specified sample sizes
sims <- tibble(people = 30, timepoints = c(6, 12, 18, 24, 30, 60)) %>% 
  mutate(
    out = map2(people, timepoints, ~simulate_estimate(.x, .y, iter = 100))
    ) %>% 
  unnest(out)
```

```{r}
#| label: fig-sim-res
#| fig-cap: Simulation study results. Each panel displays the mean posterior mean calculated over 100 iterations of model fitting. Vertical bars indicate standard errors over those 100 simulation runs. Each panel is labelled with a parameter name corresponding to the above equations. 
#| fig-width: 7

tmp <- sims %>% 
  mutate(
    result = pmap(
      list(lmer, brms, data),
      ~bind_rows(
        # Wrangle lmer results
        ..1 %>% 
          filter(Effects == "fixed") %>% 
          mutate(
            Parameter = fct_recode(
              Parameter, 
              `alpha[y]` = "(Intercept)",
              `beta[1]` = "ylag_c",
              `beta[2]` = "xlag_c"
            ),
            Centering = "Observed (lmer)"
          ),
        # Wrangle brms results
        ..2 %>% 
          filter(str_starts(Parameter, "b_|sd_|cor_|sigma")) %>% 
          mutate(
            Parameter = fct_recode(
              Parameter, 
              `alpha[x]` = "b_alphax_Intercept",
              `alpha[y]` = "b_alphay_Intercept",
              `beta[1]` = "b_betayy_Intercept",
              `beta[2]` = "b_betayx_Intercept",
              `tau[alpha[x]]` = "sd_individual__alphax_Intercept",
              `tau[alpha[y]]` = "sd_individual__alphay_Intercept",
              `tau[beta[1]]` = "sd_individual__betayy_Intercept",
              `tau[beta[2]]` = "sd_individual__betayx_Intercept",
              `rho[alpha[x]~alpha[y]]` = "cor_individual__alphax_Intercept__alphay_Intercept",
              `sigma[y]` = "sigma"
            )
          ) %>% 
          filter(!str_starts(Parameter, "cor_i")) %>% 
          mutate(Centering = "Latent (brms)") %>% 
          rename(Coefficient = Mean),
      ) %>% 
        bind_rows(
          # Observed mean of X
          ..3 %>% 
            summarise(Parameter = "alpha[x]", Coefficient = mean(x_b), Centering = "Observed (lmer)")
        )
    )
  ) %>% 
  select(1:4, result) %>% 
  unnest(result)
tmp %>%   
  ggplot(aes(nr_time, Coefficient, col = Centering, fill = Centering)) +
  scale_x_continuous(
    "Number of timepoints per person",
    breaks = extended_breaks()
  ) +
  scale_y_continuous(
    "Posterior mean",
    breaks = extended_breaks(),
    expand = expansion(.5)
  ) +
  geom_hline(
    data = pop %>% 
      select(
        `alpha[x]` = alpha_x, 
        `alpha[y]` = alpha_y, 
        `beta[1]` = beta_yy1, 
        `beta[2]` = beta_yx, 
        `tau[alpha[x]]` = tau_alpha_x, 
        `tau[alpha[y]]` = tau_alpha_y,
        `tau[beta[1]]` = tau_beta_yy1, 
        `tau[beta[2]]` = tau_beta_yx,
        `rho[alpha[x]~alpha[y]]` = cor_alpha, 
        `sigma[y]` = sigma_y
      ) %>% 
      pivot_longer(everything(), names_to = "Parameter", values_to = "Coefficient"),
    aes(yintercept = Coefficient),
    linewidth = .15
  ) +
  stat_summary(
    geom = "line", position = position_dodge(width = 2),
    fun = "mean", linewidth = .33
  ) +
  stat_summary(
    geom = "pointrange", position = position_dodge(width = 2),
    fun.data = "mean_se", fatten = 1.5, linewidth = .25
  ) +
  facet_wrap(
    "Parameter",
    nrow = 2,
    scales = "free_y",
    labeller = label_parsed
  ) +
  theme(
    legend.position = "bottom",
    strip.text = element_text(size = rel(1.1))
    )
```

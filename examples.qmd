---
title: Example analyses
---

In this document we illustrate the brms latent means syntax through various examples.

```{r}
#| label: setup
#| cache: false

library(scales)
library(brms)
library(gt)
library(posterior)
library(tidyverse)

# HMC and parallel computation options
MAX_CORES <- as.numeric(Sys.getenv("MAX_CORES"), 4)
options(
  brms.backend = Sys.getenv("BRMS_BACKEND", "rstan"), 
  brms.threads = MAX_CORES %/% 4,
  mc.cores = MAX_CORES
)

gt2 <- function(x) {
  x |> 
    gt() |> 
    fmt_number(decimals = 2, drop_trailing_zeros = TRUE) |> 
    sub_missing(missing_text = "")
}
```

## Example data

To begin with we load the example data from @mcneishPrimerTwolevelDynamic2020 that we cleaned before. These example data are 100 individuals' reports of urge to smoke (`urge`) and depression (`dep`) at 50 time points. We also have their (non-time-varying) job stress (`js`) and home stress (`hs`). We also create lagged versions of urge to smoke (`u_lag`) and depression (`u_dep`) for use in the analyses. We show these data in @tbl-data-1.

```{r}
#| label: tbl-data-1
#| tbl-cap: First six rows of the example dataset on urge to smoke and depression.

dat <- read_rds("data/mcneish-hamaker.rds") |> 
  mutate(
    u_lag = lag(urge), 
    d_lag = lag(dep), 
    .by = person
  )
dat |> 
  head() |> 
  gt2()
```

## Univariate latent means model

We begin with a univariate model of the urge to smoke. This model examines the degree of autocorrelation in the urge to smoke and how it varies between people. For individual *i* in 1...I=100 and time point *t* in 1...T=50, we model `urge` (U) as normally distributed. We model the mean on person-specific intercepts $\alpha_i$ and slopes of that person's within-person centered `urge` at a previous time point $\phi_i$. Person-specific parameters are modelled as multivariate normal on the population-level parameters (with hats). We do not model correlations between the intercepts and slopes.

First, let us pay some attention to the issue of within-person centering. Instead of decomposing urge to smoke into its within- and between-person components before fitting the model, we use "latent mean centering". What this means is that we estimate the person means along with other model parameters, and subtract those means from the observed values in one step. We refer to the latent person mean variables with an upperscript c (e.g. $U^c_{it}$).

$$
\begin{align}
U_{it} &\sim N(\alpha_i + \phi_i U^c_{it-1}, \sigma^2), \\
\begin{bmatrix}
  \alpha_i \\ \phi_i
\end{bmatrix} &\sim MVN\left(
  \begin{bmatrix}
    \bar{\alpha} \\ \bar{\phi}
  \end{bmatrix},
  \begin{pmatrix}
  \tau_\alpha \ &0 \\ 0 \ &\tau_\phi
  \end{pmatrix}
\right).
\end{align}
$$ {#eq-1}

This model is sometimes written with separate "level 1" and "level 2" equations:

$$
\begin{align}
U_{it} &\sim N(\alpha_i + \phi_i U^c_{it-1}, \sigma^2), \\
\alpha_i &= \gamma_{00} + u_{0i}, \\
\phi_i &= \gamma_{10} + u_{1i}, \\
\beta_i &= \gamma_{20} + u_{2i}, \\
\mathbf{u} &\sim MVN(\dots)
\end{align}
$$ {#eq-1.2}

We will use the R package brms [@b√ºrkner2017] to estimate this model. The following code chunk shows how to specify this model inside brms' `bf()` ("brmsformula") function. In the first line, we specify a regression equation for `urge`. Everything on the right-hand side of this formula (to the right of the tilde) is treated as a regression coefficient to be estimated from data *unless* it is the exact name of a variable in the data. Thus we will be estimating an `alpha` (intercept) and a `phi` (the autoregressive coefficient). 

The only "special" part in this syntax is `(u_lag - alpha)` that does the "latent mean centering" of the lagged urge variable. That is, it just subtracts `alpha` from each lagged value, and then uses the resulting demeaned lagged variable to predict the current urge. The first line can be considered the "level 1" equation or rather the *nonlinear* part of the model.

```{r}
#| code-fold: show

model <- bf(
  urge ~ alpha + phi * (u_lag - alpha),
  alpha ~ 1 + (1 | person),
  phi ~ 1 + (1 | person),
  nl = TRUE
)
```

The second and third lines then specify the "level 2" equation, or rather linear equations to predict the parameters in the above (potentially) nonlinear model. Both regression parameters are modelled on a population level intercept (the gamma in @eq-1.2) and person-specific deviations from it.

The fourth line specifying `nl = TRUE` is critical, because it allows us to specifically name parameters inside `bf()`, and thereby to e.g. construct the latent mean centered variable on the first row.

Note that the linear models of `alpha` and `phi` are identical. We can therefore use the following shorthand to assign them the same linear model:

```{r}
#| code-fold: show

model <- bf(
  urge ~ alpha + phi * (u_lag - alpha),
  alpha + phi ~ 1 + (1 | person),
  nl = TRUE
)
```

We will use that shorthand going forward. We could also indicate the distribution that we assume for the data. But in this work we model everything as gaussian, which is the software default and thus doesn't need to be separately indicated.

We then sample from the model. Everything from here on is standard operating procedure.

```{r}
fit <- brm(
  model,
  data = dat,
  file = "cache/brm-example-univariate"
)
```

The object `fit` now contains the estimated model (the data, posterior samples, and lots of brms-specific information). We can call `summary(fit)` to see a default summary of the model.

```{r}
summary(fit)
```

The first few rows above print information about the model (the formulas, data, and number of posterior samples). Then, "Group-Level Effects" are standard deviations (and correlations, if estimated) of the parameters that we allowed to vary across individuals (as indicated by `~person`). For each of those parameters, one row indicates its posterior summary statistics; "Estimate" is the posterior mean, "Est.Error" is the posterior standard deviation, "l-" and "u-95% CI" are the lower and upper bounds of the 95% credibility interval (so the 2.5 and 97.5 percentiles of the posterior samples). Then, Rhat is the convergence metric which should be smaller than 1.05 (optimally 1.00) to indicate that the estimation algorithm has converged. "Bulk_" and "Tail_ESS" indicate the effective sample sizes of the posterior draws, and should be pretty large.

The "Population-Level Effects" indicate the same information but for the means of the person-specific parameters' distributions; or the "fixed effects". For the average person, there is a positive autocorrelation in these data. Finally, the "Family Specific Parameters" indicate parameters that are specific to the outcome distribution. We used the default gaussian distribution, and thus get an estimated residual standard deviation.

Going forward we will create a small function to print out model summaries. It will take samples of the population level, group-level, and family-specific parameters, and return their 50th (median), 2.5th, and 97.5th quantiles.

```{r}
sm <- function(fitted_model) {
  fitted_model |> 
    as_draws_df(variable = c("b_", "sd_", "sigma"), regex = TRUE) |> 
    summarise_draws(
      ~quantile2(.x, c(.5, .025, .975))
    )
}
```

We show the results in @tbl-model-1.

```{r}
#| label: tbl-model-1
#| tbl-cap: Summaries of main parameters from the example univariate model.
fit |> 
  sm() |> 
  gt2()
```

## Multilevel AR(1) Model

We then turn to models with more than one variable of interest. In what follows we replicate "Two-Level Dynamic Structural Equation Models" (equations 4 to 7) from @mcneishPrimerTwolevelDynamic2020.

We start with the two-level AR(1) model in @mcneishPrimerTwolevelDynamic2020 (equations 4a-c). This model is similar to our example model from above, but we also now include a regression coefficient for within-person centered depression, where this centering is on the latent mean of depression. The model is

$$
\begin{align}
U_{it} &\sim N(\alpha_i + \phi_i U^c_{it-1} + \beta_i D^c_{it}, \sigma^2), \\
U^{c}_{it} &= U^{\text{raw}}_{it} - \alpha^U_i, \\
D^{c}_{it} &= D^{\text{raw}}_{it} - \alpha^D_i, \\
\begin{bmatrix}
  \alpha^U_i \\ \alpha^D_i \\ \phi_i \\ \beta_i
\end{bmatrix} &\sim MVN\left(
  \begin{bmatrix}
    \bar{\alpha^U} \\ \bar{\alpha^D} \\ \bar{\phi} \\ \bar{\beta_i}
  \end{bmatrix},
  \begin{pmatrix}
    \tau_\alpha^U \ &0 \ &0 &0 \\ 
    0 \ &\tau_\alpha^D \ &0 \ &0 \\ 
    0 \ &0 \ &\tau_\beta \ &0 \\
    0 \ &0 \ &0 \ &\tau_\phi
  \end{pmatrix}
\right)
\end{align}
$$ {#eq-2}

We then see from @eq-2 that we need to refer to different outcomes' parameters across model formulas. That is, when predicting the urge to smoke, we need a way to refer to the (latent) mean of depression so that we can appropriately center the depression predictor. Currently brms does not support sharing parameters across formulas for different outcomes, but we can overcome this limitation with a small data wrangling trick

That is, we "stack" our data into the long format with respect to the two different outcomes, urge to smoke and depression. Then, on each row we have all variables from that measurement occasion, in addition to new ones that indicate the value of the outcome, and which outcome it refers to (@tbl-data-2).

```{r}
#| label: tbl-data-2
#| tbl-cap: Rearranged data for multivariate models.

dat <- dat |> 
  select(-js, -hs) |> 
  pivot_longer(c(urge, dep), names_to = "outcome") |> 
  mutate(
    i_urge = if_else(outcome == "urge", 1, 0),
    i_dep = if_else(outcome == "dep", 1, 0)
  ) |> 
  # Include predictors from each row
  left_join(dat)

dat |> 
  head() |> 
  gt2()
```

Now we can model `value` and use `i_urge` and `i_dep` to control whether a parameter should apply to the outcome on a particular row. So here we want alpha, phi, and beta to apply to urge, but depb to depression. Then we can use depb to create the predictor for urge on the fly.

```{r}
#| code-fold: show

bform <- bf(
  value ~ 
    i_urge * (alpha1 + phi * (u_lag - alpha1) + beta * (dep - alpha2)) + 
    i_dep * alpha2,
  nlf(sigma ~ i_urge * sigma1 + i_dep * sigma2),
  alpha1 + phi + beta + alpha2 ~ 1 + (1 | person),
  sigma1 + sigma2 ~ 1,
  nl = TRUE
)
```

Sample from model

```{r}
fit <- brm(
  bform,
  data = dat,
  control = list(adapt_delta = 0.95),
  file = "cache/brm-example-4"
)
```

Compare model summary to @mcneishPrimerTwolevelDynamic2020. We can see the estimates match to within differences in priors and MCSE. Note in the code I transform standard deviations by first exponentiating draws of residual standard deviations, and then square to put them on the variance scale as in @mcneishPrimerTwolevelDynamic2020.

```{r}
source("mplus-parameters.R")
as_draws_df(fit, variable = c("b_", "sd_"), regex = TRUE) %>% 
  mutate(
    across(starts_with("sd_"), ~.^2),
    across(starts_with("b_sigma"), ~exp(.)^2)
  ) |> 
  summarise_draws(
    brms = ~quantile2(., probs = c(.5, .025, .975)) |> 
      number(.01) |> 
      str_glue_data("{q50} [{q2.5}, {q97.5}]")
  ) |> 
  mutate(
    variable = str_replace(variable, "sd_person__", "var_"),
    mplus = mplus$equation.4$mplus
  ) |> 
  gt2()
```

## Time-Invariant Covariates

This is as above but includes time-invariant covariates js and hs, and the between-person effect of depression on urge. I label the latter as "gamma03" as in Equation 5 in @mcneishPrimerTwolevelDynamic2020. Note also that I must include it in the regression equation for the outcome, and not in the "level 2" equation because the latter must be "linear formulas" in brms. There's probably other ways of doing it too.

```{r}
#| code-fold: show

bform <- bf(
  value ~ 
    i_urge * 
    (alpha1 + phi * (u_lag - alpha1) + beta * (dep - alpha2) + gamma03 * alpha2) + 
    i_dep * alpha2,
  nlf(sigma ~ i_urge * sigma1 + i_dep * sigma2),
  alpha1 + phi + beta ~ 1 + js + hs + (1 | person),
  alpha2 ~ 1 + (1 | person),
  gamma03 + sigma1 + sigma2 ~ 1,
  nl = TRUE
)
```

With flat priors the gamma03 parameter is wonky so I set a normal(0, 3) on it.

```{r}
p <- get_prior(bform, dat)
p <- p |> 
  mutate(
    prior = case_when(
      class == "b" & nlpar != "gamma03" ~ "normal(0, 1)",
      class == "b" & nlpar == "gamma03" ~ "normal(0, 3)",
      class == "sd" ~ "student_t(7, 0, 1)",
      TRUE ~ prior
    )
  )
```

Sample from model

```{r}
fit <- brm(
  bform,
  data = dat,
  prior = p,
  control = list(adapt_delta = 0.99),
  file = "cache/brm-example-5",
)
```

Model summary.

```{r}
as_draws_df(fit, variable = c("b_", "sd_"), regex = TRUE) %>% 
  mutate(
    across(starts_with("sd_"), ~.^2),
    across(starts_with("b_sigma"), ~exp(.)^2)
  ) |> 
  summarise_draws(
    brms = ~quantile2(., probs = c(.5, .025, .975)) |> 
      number(.01) |> 
      str_glue_data("{q50} [{q2.5}, {q97.5}]")
  ) |> 
  mutate(
    variable = str_replace(variable, "sd_person__", "var_"),
    mplus = mplus$equation.5$mplus
  ) |> 
  gt() |> 
  fmt_number(decimals = 2)
```

## Multilevel Location-Scale model

Equations 5 and 6 in @mcneishPrimerTwolevelDynamic2020.

```{r}
#| code-fold: show

bform <- bf(
  value ~ 
    i_urge * 
    (alpha1 + phi * (u_lag - alpha1) + beta * (dep - alpha2) + gamma03 * alpha2) + 
    i_dep * alpha2,
  nlf(sigma ~ i_urge * sigma1 + i_dep * sigma2),
  alpha1 + phi + beta ~ 1 + js + hs + (1 | person),
  alpha2 + sigma1 + sigma2 ~ 1 + (1 | person),
  gamma03 ~ 1,
  nl = TRUE
)
```

Sample from model

```{r}
fit <- brm(
  bform,
  data = dat,
  prior = p,
  control = list(adapt_delta = 0.99),
  file = "cache/brm-example-6"
)
```

Model summary. These match.

```{r}
as_draws_df(fit, variable = c("b_", "sd_"), regex = TRUE) %>% 
  mutate(
    across(starts_with("sd_"), ~.^2),
    across(starts_with("b_sigma"), ~exp(.)^2)
  ) |> 
  summarise_draws(
    brms = ~quantile2(., probs = c(.5, .025, .975)) |> 
      number(.01) |> 
      str_glue_data("{q50} [{q2.5}, {q97.5}]")
  ) |> 
  mutate(
    variable = str_replace(variable, "sd_person__", "var_")
  ) |> 
  gt() |> 
  fmt_number(decimals = 2)
```

## Multilevel VAR(1) Model

Equations 7 and 8 in @mcneishPrimerTwolevelDynamic2020.

```{r}
#| code-fold: show

bform <- bf(
  value ~ 
    i_urge * (alpha1 + phi1 * (u_lag - alpha1) + phi4 * (d_lag - alpha2)) + 
    i_dep * (alpha2 + phi2 * (d_lag - alpha2) + phi3 * (u_lag - alpha1)),
  nlf(sigma ~ i_urge * sigma1 + i_dep * sigma2),
  alpha1 + alpha2 + phi1 + phi2 + phi3 + phi4 + sigma1 + sigma2 ~ 1 + (1 | person),
  nl = TRUE
)
```

Sample

```{r}
fit <- brm(
  bform,
  data = dat,
  control = list(adapt_delta = 0.99),
  file = "cache/brm-example-7"
)
```

Summarise. I wasn't sure how to transform the variance components here to match the variances on the link function scale so left them as is.

```{r}
as_draws_df(fit, variable = c("b_", "sd_"), regex = TRUE) %>% 
  mutate(
    across(starts_with("sd_"), ~.^2)
  ) |> 
  summarise_draws(
    brms = ~quantile2(., probs = c(.5, .025, .975)) |> 
      number(.01) |> 
      str_glue_data("{q50} [{q2.5}, {q97.5}]")
  ) |> 
  mutate(
    variable = str_replace(variable, "sd_person__", "var_"),
    mplus = mplus$equation.7$mplus
  ) |> 
  gt2()
```

## Social media use

```{r}
d <- read_rds("data/beyens-etal.rds")

# Rescale everything to the unit interval
d <- d |> 
  mutate(
    across(c(sm), ~./60),
    across(starts_with("wb"), ~./7)
    )

d <- d |> 
  pivot_longer(c(sm, wb), names_to = "outcome") |> 
  mutate(
    i_wb = if_else(outcome == "wb", 1, 0),
    i_sm = if_else(outcome == "sm", 1, 0)
  ) |> 
  # Include predictors from each row
  left_join(d)
```

We regress wellbeing on an autocorrelative term and within person effect of passive social media use. Include correlations between person parameters; one of these will be the between-person relationship.

```{r}
bform <- bf(
  value ~ 
    i_wb * (alpha1 + phi * (wb_lag - alpha1) + beta * (sm - alpha2)) + 
    i_sm * alpha2,
  nlf(sigma ~ i_wb * sigma1 + i_sm * sigma2),
  alpha1 + alpha2 + phi + beta ~ 1 + (1 |p| person),
  sigma1 + sigma2 ~ 1,
  nl = TRUE
)
```

```{r}
fit <- brm(
  bform,
  data = d,
  control = list(adapt_delta = 0.95),
  file = "cache/brm-example-sm-1"
)
```

```{r}
as_draws_df(fit, variable = c("b_", "sd_"), regex = TRUE) %>% 
  mutate(
    across(starts_with("sd_"), ~.^2),
    across(starts_with("b_sigma"), ~exp(.)^2)
  ) |> 
  summarise_draws(
    mean, sd, ~quantile2(.x, c(.025, .975))
  )
  gt2()
```

## Social media use 2

Same as above but a three-level model class > person > observation.

```{r}
bform <- bf(
  value ~ 
    i_wb * (alpha1 + phi * (wb_lag - alpha1) + beta * (sm - alpha2)) + 
    i_sm * alpha2,
  nlf(sigma ~ i_wb * sigma1 + i_sm * sigma2),
  alpha1 + alpha2 + phi + beta ~ 1 + (1 |p| person) + (1 |c| class),
  sigma1 + sigma2 ~ 1,
  nl = TRUE
)
```

```{r}
fit <- brm(
  bform,
  data = d,
  control = list(adapt_delta = 0.95),
  file = "cache/brm-example-sm-threelevel"
)
```

```{r}
as_draws_df(fit, variable = c("b_", "sd_"), regex = TRUE) %>% 
  mutate(
    across(starts_with("sd_"), ~.^2),
    across(starts_with("b_sigma"), ~exp(.)^2)
  ) |> 
  summarise_draws(
    mean, sd, ~quantile2(.x, c(.025, .975))
  )
  gt2()
```

## Conclusion

We estimated models 4-7 in @mcneishPrimerTwolevelDynamic2020 with brms and got very similar if not identical results.
